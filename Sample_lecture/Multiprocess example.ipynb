{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, typeof, int32, int64, float32, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writting parallel code\n",
    "\n",
    "The goal is to desing parallel programs that are flexible, efficient and simple.\n",
    "\n",
    "Step 0: Start by profiling a serial program to identify bottlenecks\n",
    "\n",
    "Step 1: Are there for opportunities for parallelism?\n",
    "\n",
    "1. Can tasks be perforemd in parallel?\n",
    "   \n",
    "   A. Function calls \n",
    "   \n",
    "   B.Loops\n",
    "\n",
    "2. Can data be split and operated on in parallel?\n",
    "\n",
    "    A. Decomposition of arrays along rows, columns, blocks\n",
    "    \n",
    "    B. Decomposition of trees into sub-trees\n",
    "\n",
    "3. Is there a pipeline with a sequence of stages?\n",
    "\n",
    "    A. Data preprocesing and analysis\n",
    "    \n",
    "    B. Graphics rendering\n",
    "\n",
    "\n",
    "Step 2: What is the nature of the parallelism?\n",
    "\n",
    "1. Linear\n",
    "\n",
    "    Embarassingly parallel programs\n",
    "    \n",
    "2. Recursive\n",
    "\n",
    "    Adaptive partitioning methods\n",
    "    \n",
    "Step 3: What is the granularity?\n",
    "\n",
    "1. 10s of jobs\n",
    "\n",
    "2. 1000s of jobs\n",
    "\n",
    "Step 4: Choose an algorihtm\n",
    "\n",
    "1. Organize by tasks\n",
    "\n",
    "2. Organize by data\n",
    "\n",
    "3. Organize by flow\n",
    "\n",
    "Step 5: Map to program and data structures\n",
    "\n",
    "Program structures\n",
    "\n",
    "Single program multiple data (SPMD)\n",
    "\n",
    "Master/worker\n",
    "\n",
    "Loop parallelism\n",
    "\n",
    "Fork/join\n",
    "\n",
    "Data structures\n",
    "\n",
    "Shared data\n",
    "\n",
    "Shared queue\n",
    "\n",
    "Distributed array\n",
    "\n",
    "Step 6: Map to parallel environment\n",
    "\n",
    "Multi-core shared memrory\n",
    "\n",
    "Cython with OpenMP\n",
    "\n",
    "multiprocessing\n",
    "\n",
    "IPython.cluster\n",
    "\n",
    "Multi-computer\n",
    "\n",
    "IPython.cluster\n",
    "\n",
    "MPI\n",
    "\n",
    "Hadoop / Spark\n",
    "\n",
    "GPU\n",
    "\n",
    "CUDA\n",
    "\n",
    "OpenCL\n",
    "\n",
    "Step 7: Execute, debug, tune in parallel environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Estimating Pi\n",
    "\n",
    "This is clearly a toy example, but the template cna be used for most embarassingly parallel problems. First we see how much we can speed-up the serial code by the use of compilation, then we apply parallel processing for a furhter linear speed-up in the number of processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_python(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if (x**2 + y**2) < 1:\n",
    "            s += 1\n",
    "    return s/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "stats = %prun -r -q pi_python(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4000004 function calls in 1.273 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 6 to 5 due to restriction <5>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.746    0.746    1.273    1.273 <ipython-input-5-5ece63c5fe8a>:1(pi_python)\n",
      "  2000000    0.425    0.000    0.527    0.000 random.py:367(uniform)\n",
      "  2000000    0.102    0.000    0.102    0.000 {method 'random' of '_random.Random' objects}\n",
      "        1    0.000    0.000    1.273    1.273 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    1.273    1.273 <string>:1(<module>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1f2c186e9e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sort_stats('time').print_stats(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_numpy(n):\n",
    "    xs = np.random.uniform(-1, 1, (n,2))\n",
    "    return 4.0*((xs**2).sum(axis=1).sum() < 1)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def pi_numba(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        if x**2 + y**2 < 1:\n",
    "            s += 1\n",
    "    return s/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.1 ms ± 811 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.23 ms ± 17.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "4.24 ms ± 46.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "n = int(1e5)\n",
    "%timeit pi_python(n)\n",
    "%timeit pi_numba(n)\n",
    "%timeit pi_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigger the problem, the more scope there is for parallelism\n",
    "\n",
    "Amhdahls’ law says that the speedup from parallelization is bounded by the ratio of parallelizable to irreducibly serial code in the aloorithm. However, for big data analysis, Gustafson’s Law is more relevant. This says that we are nearly always interested in increasing the size of the parallelizable bits, and the ratio of parallelizable to irreducibly serial code is not a static quantity but depends on data size. For example, Gibbs sampling has an irreducibly serial nature, but for large samples, each iteration may be able perform PDF evaluations in parallel for zillions of data points.\n",
    "\n",
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_procs = multiprocessing.cpu_count()\n",
    "num_procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pimulti.py\n"
     ]
    }
   ],
   "source": [
    "%%file pimulti.py\n",
    "import numpy as np\n",
    "def pi_numpy2(n):\n",
    "    xs = np.random.uniform(-1, 1, (n,2))\n",
    "    return 4.0*((xs**2).sum(axis=1).sum() < 1)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pimulti as pm\n",
    "n = int(1e5)\n",
    "%time pi_numpy(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pi_multiprocessing(n):\n",
    "   \n",
    "    num_procs = multiprocessing.cpu_count()\n",
    "    \"\"\"Split a job of length n into num_procs pieces.\"\"\"\n",
    "    m = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(m)\n",
    "    results = pool.map(pm.pi_numpy2, [n//m]*m)\n",
    "    pool.close()\n",
    "    return(np.mean(results))\n",
    "pi_multiprocessing(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3113c496edc2>\u001b[0m in \u001b[0;36mpi_numpy\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpi_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m4.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.uniform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont2_array_sc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = int(1e10)\n",
    "%time pi_numpy(n)\n",
    "%time pi_multiprocessing(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
